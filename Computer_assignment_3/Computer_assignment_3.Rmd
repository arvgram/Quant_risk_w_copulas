---
title: "Assignment3"
author: "Anton LinnÃ©r"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(evd)
library(SimCop)
library(copula)
```

\\section(Random number generation from bivariate EVD) \\subsection(Parametric bivariate EV models) In the package \texttt{evd} the nine models and their respective dependence and asymmetry parameters are:


\begin{itemize}
    \item Logistic. Dependence parameter $\texttt{r}$ between (0,1]. Smaller \texttt{r} implies higher dependence.
    \item Asymmetrix logistic. Dependence parameter r, as in (symmetric) Logistic. Asymmetry parameters are $\texttt{t}_1$ and $\texttt{t}_2$. Indepence if any of $\texttt{t}_1, \texttt{t}_2$ are 0 or $\texttt{r = 1}$. For complete dependence $\texttt{t}_1= \texttt{t}_2$=1 and $\texttt{r} \rightarrow 0$.
    \item Husler-Reiss. Dependence parameter \texttt{r} $\in (0, \infty)$. Full dependence as $\texttt{r}$ $\rightarrow \infty$, and independence as $\texttt{r} \rightarrow 0$
    \item Negative logistic. Dependence parameter $\texttt{r}$ $>0$. Higher $\texttt{r}$ implies higher dependence. 
    \item Asymmetric negative logistic. Dependence parameter $\texttt{r}>0$ and asymmetry parameters $\texttt{t}_1,\texttt{t}_2$ $\in (0, 1]$. Indepence if any of $\texttt{t}_1,\texttt{t}_2, \texttt{r}$  approaches 0. Complete dependence if $\texttt{t}_1,\texttt{t}_2 = 1,1$ and $\texttt{r} \rightarrow \infty$.
    \item Bilogistic. Parameters $\alpha, \beta$. When $\alpha = \beta$ the model is equivalent to logistic with dependence parameter $\texttt{r} =\alpha$. As in logistic, when $\alpha = \beta =  \texttt{r} \rightarrow 0$ the model tends to complete dependence. Independence as either both tends to 1, or one is fix and other tends to 1.
    \item Negative bilogistic Parameters $\alpha, \beta$. When $\alpha = \beta$ the model is equivalent to negative bilogistic with dependence parameter $\texttt{r} =1\alpha$. When $\alpha = \beta \rightarrow 0$ the model tends to complete dependence. Independence as either both tends to $\infty$, or one is fix and other tends to $\infty$.
    \item Coles-Tawn. Parameters $\alpha, \beta > (0,0)$. As $\alpha = \beta \rightarrow \infty$ the model shows complete dependence. Independence as either both tends to 0, or one is fix and other tends to 0.
    \item Asymmetric mixed distribution. Parameters $\alpha, \beta$ fulfill the following conditions: $\alpha$ and $\alpha + 3 \beta > 0$, and $\alpha + 2\beta$, $\alpha + \beta \leq 1$ As $\beta$ is fix, the strength of dependence increases with $\alpha$. Complete dependence is not achievable. Independence as $\alpha = \beta = 0$.
  \end{itemize}
```{r 2.2}
par(mfrow=c(2,2))
sim1 = rbvevd(200,dep=0.001, model = "hr") #HR
plot(sim1)
sim2 = rbvevd(200,dep=5, model = "hr") #HR
plot(sim2)

sim3 = rbvevd(200,dep=0.001, asy=c(0.5,1), model = "aneglog") #HR
plot(sim3)
sim4 = rbvevd(200,dep=5,asy=c(0.5,1), model = "aneglog") #HR
plot(sim4)
#Hustler Reiss
(cor(sim1[,1],sim1[,2]))
(cor(sim2[,1],sim2[,2]))

(cor(sim1[,1],sim1[,2], method = "kendall"))
(cor(sim2[,1],sim2[,2], method = "kendall"))

(cor(sim1[,1],sim1[,2], method = "spearman"))
(cor(sim2[,1],sim2[,2], method = "spearman"))
# "A neglog"
(cor(sim3[,1],sim3[,2]))
(cor(sim4[,1],sim4[,2]))

(cor(sim3[,1],sim3[,2], method = "kendall"))
(cor(sim4[,1],sim4[,2], method = "kendall"))

(cor(sim3[,1],sim3[,2], method = "spearman"))
(cor(sim4[,1],sim4[,2], method = "spearman"))

```
\newpage
For the bivariate cases we have:
\begin{itemize}
    \item Bivariate Extreme Value Logistic Copula: dependence parameter $r \geq 1$. 
    \item Bivariate Extreme Value Asymmetric Logistic Copula dependence parameter $r \leq 1$, asymmetry parameters $\theta, \phi \in [0,1]$. If both are $1$ then this is a symmetric logistic.
    \item Bivariate Extreme Value Mixed Model Copula: parameter $0\leq\theta\leq1$
    \item Bivariate Extreme Value Asymmetric Mixed Model Copula: parameters $\theta, \phi$. These fulfill the following conditions, $\theta \geq 0$, $\theta + 3\phi \geq 0$, $\theta+\phi \leq 1$, $\theta + 2\phi \leq 1$.
    \item Bivariate Extreme Value Spline Copula. Parameter: a spline function for the dependence function. 
\end{itemize}
As for the multivariate copulas we have
\begin{itemize}
    \item Multivariate Extreme Value Asymmetric Logistic Copula: $\mathbf{\theta}$, matrix with asymmetry parameters. $\mathbf{r}$, vector with dependency parameters. Terms and conditions apply. 
    \item Multivariate Extreme Value Gumbel Copula. Dependence parameter $r \geq 1$.
    \item Multivariate Clayton Copula. Dependence parameter $\theta > 0$ 
    \item Multivariate Frank Copula. Parameter $\alpha > 0$
\end{itemize}
\subsection{Exercise 2.4}
```{r Exercise 2.4}
par(mfrow=c(3,2))
cop1 = NewBEVAsyLogisticCopula(2, 200, 0.5)
approxcop1 = GetApprox(cop1)
RV1 = GenerateRV(approxcop1, 200)
plot(RV1)

cop1 = NewBEVAsyLogisticCopula(20, 0.5, 0.5)
approxcop1 = GetApprox(cop1)
RV1 = GenerateRV(approxcop1, 200)
plot(RV1)

cop1 = NewBEVAsyLogisticCopula(2, 0.5, 0.5)
approxcop1 = GetApprox(cop1)
RV1 = GenerateRV(approxcop1, 200)
plot(RV1)

cop1 = NewBEVAsyLogisticCopula(2, 1, 0.5)
approxcop1 = GetApprox(cop1)
RV1 = GenerateRV(approxcop1, 200)
plot(RV1)

cop1 = NewBEVAsyLogisticCopula(2, 0.5, 0.5)
approxcop1 = GetApprox(cop1)
RV1 = GenerateRV(approxcop1, 200)
plot(RV1)

cop1 = NewBEVAsyLogisticCopula(2, 0.5, 1)
approxcop1 = GetApprox(cop1)
RV1 = GenerateRV(approxcop1, 200)
plot(RV1)

```

\section{Exercise 3}
```{r data}
fre = source("https://www.maths.lth.se/matstat/kurser/fmsn15masm23/datasets/fremantle.R")
port = source("https://www.maths.lth.se/matstat/kurser/fmsn15masm23/datasets/portpirie.R")
```

\subsection{Exercise 3.1}

```{r Exercise 3.1}
fre.years = fre$value$Year
port.years = port$value$Year
```

```{r Exercise 3.2}
tot.years = merge(x = fre$value,y = port$value, by = "Year")
tot.years = tot.years[,-1]
tot.years = tot.years[,-2]
 
```

```{r Exercise 3.3}
library(fitdistrplus)
par(mfrow=c(1,1))
plot(tot.years$SeaLevel.x, tot.years$SeaLevel.y, xlab = "Fremantle max sea level", ylab = "Portpirie max sea level", main="Annual max sea level scatter plot")
```
```{r Exercise 3.4 Parametric}
par(mfrow=c(2,1))
#FML:
#aneglog
ml.fml1 = fbvevd(tot.years, model = c("aneglog"))
#Hr
ml.fml2 = fbvevd(tot.years, model = c("hr"))

#IFM
start1 = list(loc=1, scale = 1, shape = 1)
start2 = list(loc = 3,scale=3,shape = 1)

marg.fit1 = mledist(tot.years[,1], "gev", start = start1)$est
marg.fit2 = mledist(tot.years[,2], "gev", start = start2)$est

#IFM for aneglog
(ml.ifm1 = fbvevd(tot.years, model= c("aneglog"), loc1 = marg.fit1["loc"], scale1 = marg.fit1["scale"], shape1=marg.fit1["shape"],loc2 = marg.fit2["loc"], scale2 = marg.fit2["scale"], shape2=marg.fit2["shape"]))
#IFM for Hr
(ml.ifm2 = fbvevd(tot.years, model= c("hr"), loc1 = marg.fit1["loc"], scale1 = marg.fit1["scale"], shape1=marg.fit1["shape"],loc2 = marg.fit2["loc"], scale2 = marg.fit2["scale"], shape2=marg.fit2["shape"]))

```

```{r 3.5 Non-parametric}
nonpar.gev = abvnonpar(data = tot.years, plot = TRUE)
nonpar.emp = abvnonpar(data = tot.years, plot = TRUE, epmar = TRUE) #Can see that non-empircal transformation shows more indep. 

```

```{r 3.6 Estimates probabilities}
#We have different calcs for A. 

#PARAMETRIC
# a) Asymmetric FML
mar1 = c( ml.fml1$estimate["loc1"],  ml.fml1$estimate["scale1"],  ml.fml1$estimate["shape1"])
mar2 = c( ml.fml1$estimate["loc2"],  ml.fml1$estimate["scale2"],  ml.fml1$estimate["shape2"])
dep =  ml.fml1$estimate["dep"]
asy = c( ml.fml1$estimate["asy1"], ml.fml1$estimate["asy2"])

(prob1 = pbvevd(c(1.7,4.2), dep = dep, asy = asy, mar1=mar1, mar2=mar2, model = c("aneglog"), lower.tail = FALSE)) 

(prob2 = pbvevd(c(1.8,4.4), dep = dep, asy = asy, mar1=mar1, mar2=mar2, model = c("aneglog"), lower.tail = FALSE))

(prob3 = 1 - pbvevd(c(1.478,3.850), dep = dep, asy = asy, mar1=mar1, mar2=mar2, model = c("aneglog")))

mar1 = c( ml.fml2$estimate["loc1"],  ml.fml2$estimate["scale1"],  ml.fml2$estimate["shape1"])
mar2 = c( ml.fml2$estimate["loc2"],  ml.fml2$estimate["scale2"],  ml.fml2$estimate["shape2"])
dep =  ml.fml2$estimate["dep"]
(prob1.sym = pbvevd(c(1.7,4.2), dep = dep, mar1=mar1, mar2=mar2, model = c("hr"), lower.tail = FALSE))
(prob2.sym = pbvevd(c(1.8,4.4), dep = dep, mar1=mar1, mar2=mar2, model = c("hr"), lower.tail = FALSE))
(prob3.sym = 1- pbvevd(c(1.478,3.850), dep = dep, mar1=mar1, mar2=mar2, model = c("hr")))

```


```{r empirical probs}
prob1.emp <- as.numeric(tot.years$SeaLevel.x > 1.7 & tot.years$SeaLevel.y > 4.2)
(prob1.emp = sum(prob1.emp)/length(prob1.emp))

prob2.emp <- as.numeric(tot.years$SeaLevel.x > 1.8 & tot.years$SeaLevel.y > 4.4)
(prob2.emp = sum(prob2.emp)/length(prob2.emp))


prob3.emp <- as.numeric(tot.years$SeaLevel.x >=  1.478 | tot.years$SeaLevel.y >= 3.850)
(prob3.emp = sum(prob3.emp)/length(prob3.emp))
```

```{r non-parametric}
G_star <- function(x,y){
  val = exp(-(1/x + 1/y)*abvnonpar(x=x/(x+y), data=tot.years ))
  return(val)
}

transform <- function(x, mar){
  mar1 = mar
  x.t = c((1+mar1[3]*(x-mar1[1])/mar1[2])^(1/mar1[3]), use.names=FALSE) 
return(x.t)}

#WHAT MARGIN PARAMS SHOULD I USE HERE?
#aYBE


#1.7 and 4.2
x.t = transform(1.7, mar1)
y.t = transform(4.2, mar2)
(prob1.nonpar = 1 - pgev(1.7, loc=mar1[1], scale=mar1[2], shape = mar1[3]) - pgev(4.2, loc=mar2[1], scale=mar2[2], shape = mar2[3]) + G_star(x.t, y.t))

#1.8 and 4.4
x.t = transform(1.8,  mar1)
y.t = transform(4.4,  mar2)
(prob2.nonpar = 1 - pgev(1.8, loc=mar1[1], scale=mar1[2], shape = mar1[3]) - pgev(4.4, loc=mar2[1], scale=mar2[2], shape = mar2[3]) + G_star(x.t, y.t))

#1.478 and 3.850
x.t = transform(1.478, mar1)
y.t = transform(3.850,  mar2)
(prob3.nonpar = 1 - G_star(x.t, y.t))
```


```{r 3.7}

#By using bayes relation betweenn conditional probabilities we get:
#Non.par
x.t1 = transform(1.478, mar1)
y.t1 = transform(3.850, mar2)
x.t2 = transform(1.95, mar1)
y.t2 = transform(4.8, mar2)
(prob1 = ((1 - G_star(x.t1, y.t1)) - (1 - G_star(1.95, 4.8)))/ (1 - G_star(x.t1, y.t1)))

#par (symmetric)
x.t1 = transform(1.478, mar1)
y.t1 = transform(3.850, mar2)
x.t2 = transform(1.95, mar1)
y.t2 = transform(4.8, mar2)
(prob1 =  (pbvevd(c(1.478,3.850), dep = dep, mar1=mar1, mar2=mar2, model = c("hr"), lower.tail = FALSE) -  (pbvevd(c(1.95,4.8), dep = dep, mar1=mar1, mar2=mar2, model = c("hr"), lower.tail = FALSE))/pbvevd(c(1.478,3.850), dep = dep, mar1=mar1, mar2=mar2, model = c("hr"), lower.tail = FALSE)))
```

```{r 3.8 plotting}
par(mfrow=c(2,2))
ml.fml2 = fbvevd(tot.years, model = c("hr"))
plot(ml.fml2, which=5, p=c(0.75, 0.9, 0.95))
qcbvnonpar(data = tot.years, plot=TRUE)
qcbvnonpar(data = tot.years, plot=TRUE, epmar = TRUE)
```

```{r 3.9 }
tot.years = merge(x = fre$value,y = port$value, by = "Year")


# min and max
minv <- min(tot.years["Year"])
maxv <- max(tot.years["Year"])

# Normalize to [-1, 1]
tot.years["Year"] <- ((tot.years["Year"] - minv) / (maxv - minv)) * 2 - 1

x_dat = tot.years[-1]
x_dat = x_dat[-2]

#Test bitg
ml.fml1.2 = fbvevd(x_dat, model = c("aneglog"),nsloc1 =tot.years["Year"],nsloc2 =tot.years["SOI"])
#Hr
ml.fml2.2 = fbvevd(x_dat, model = c("hr"), nsloc1 =tot.years["Year"],nsloc2 =tot.years["SOI"])
anova(ml.fml1.2, ml.fml1)

(A <- logLik(ml.fml1))
(B<- logLik(ml.fml1.2))

(stat <- -2 * (as.numeric(A)-as.numeric(B)))
(p.val <- pchisq(stat, df = 2, lower.tail = FALSE)) #under 0.05 we should use the complex model ( reject null)


(A <- logLik(ml.fml2))
(B<- logLik(ml.fml2.2))

(stat <- -2 * (as.numeric(A)-as.numeric(B)))
(p.val <- pchisq(stat, df = 2, lower.tail = FALSE)) #under 0.05 we should use the complex model ( reject null)

#Test "YEAR" ----------------------------

ml.fml1.2 = fbvevd(x_dat, model = c("aneglog"),nsloc1 =tot.years["Year"])
#Hr
ml.fml2.2 = fbvevd(x_dat, model = c("hr"), nsloc1 =tot.years["Year"])

(A <- logLik(ml.fml1))
(B<- logLik(ml.fml1.2))

(stat <- -2 * (as.numeric(A)-as.numeric(B)))
(p.val <- pchisq(stat, df = 1, lower.tail = FALSE)) #under 0.05 we should use the complex model ( reject null)


(A <- logLik(ml.fml2))
(B<- logLik(ml.fml2.2))

(stat <- -2 * (as.numeric(A)-as.numeric(B)))
(p.val <- pchisq(stat, df = 1, lower.tail = FALSE)) #under 0.05 we should use the complex model ( reject null)



#Test SOI ---------------------------------------
ml.fml1.2 = fbvevd(x_dat, model = c("aneglog"),nsloc1 =tot.years["SOI"])
#Hr
ml.fml2.2 = fbvevd(x_dat, model = c("hr"), nsloc1 =tot.years["SOI"])

(A <- logLik(ml.fml1))
(B<- logLik(ml.fml1.2))

(stat <- -2 * (as.numeric(A)-as.numeric(B)))
(p.val <- pchisq(stat, df = 1, lower.tail = FALSE)) #under 0.05 we should use the complex model ( reject null)


(A <- logLik(ml.fml2))
(B<- logLik(ml.fml2.2))

(stat <- -2 * (as.numeric(A)-as.numeric(B)))
(p.val <- pchisq(stat, df = 1, lower.tail = FALSE))


#Conclusion, SOI is statisctically significant!
```

```{r Exercise 4}
#Get margins to use in FML
marg.fit1 = mledist(tot.years[,1], "gev", start = start)$est
marg.fit2 = mledist(tot.years[,2], "gev", start = start)$est

#Get some tau
tau = 0.2

#Copulas
gumbel.cop <- gumbelCopula(iTau(gumbelCopula(), tau))
galambos.cop <- galambosCopula (iTau(galambosCopula(), tau))
hr.cop <-huslerReissCopula(iTau(huslerReissCopula(), tau))
# Can this be canonical method?

gumb.fit = fitCopula(gumbel.cop, data = pobs(tot.years))
galamb.fit = fitCopula(galambos.cop, data = pobs(tot.years))
hr.fit = fitCopula(hr.cop, data = pobs(tot.years))

#help
gumb.mvdc = mvdc(gumbel.cop, margins = c("gev", "gev") , paramMargins = list(list(loc=marg.fit1[1], scale = marg.fit1[2], shape=marg.fit1[3]),list(loc=marg.fit2[1], scale = marg.fit2[2], shape=marg.fit2[3])))

param= c(1,1,1,1,1,1,1)
param = c(marg.fit1, marg.fit2, 0.2, use.names = FALSE)

(gumb.mvdc.fit = fitMvdc(as.matrix(tot.years), mvdc = gumb.mvdc, start=param, method = "Nelder"))

gumb.mvdc = mvdc(gumbel.cop, margins = c("gev", "gev") , paramMargins = list(list(loc=marg.fit1[1], scale = marg.fit1[2], shape=marg.fit1[3]),list(loc=marg.fit2[1], scale = marg.fit2[2], shape=marg.fit2[3])))


#Regular EV dists. 
(ml.neglog = fbvevd(tot.years, model= c("neglog")))
(ml.log = fbvevd(tot.years, model= c("log")))
(ml.hr = fbvevd(tot.years, model= c("hr") ))

(ml.neglog2 = fbvevd(tot.years, model= c("neglog"), method = c("ml")))
(ml.log2 = fbvevd(tot.years, model= c("log")))
(ml.hr2 = fbvevd(tot.years, model= c("hr") ))
```

```{r start with ranking data}
tot.years[1] = rank(tot.years$SeaLevel.x)
tot.years[2] = rank(tot.years$SeaLevel.y)
#Emp dist func evald at 12
emp.dist = function(data, point){
  val = sum(data < point)/(length(data)+1)
return(val)}

```

```{r exercise 4.3}
gof1 = gofEVCopula(gumb.fit@copula, as.matrix(tot.years))

gof2 = gofEVCopula(galamb.fit@copula, as.matrix(tot.years))

gof3 = gofEVCopula(hr.fit@copula, as.matrix(tot.years))


```

```{r exercise 4.4}
w = seq(0,1, by=0.01)
cfg = An.biv(tot.years, w, estimator=c("CFG"))
pickands =  An.biv(tot.years, w, estimator=c("Pickands"))

par(mfrow=c(2,1))
plot(cfg)
plot(pickands)
```

```{r Exercise 4.5}
#Parametric


```


\newline
\section{Exercise 5}

We see that we don't force convexity the result plot is not convex. How ever, enforcing convexity only leaves 13 points withing the hull.

```{r exercise 5.1}
A1 = NonparEstDepFct(tot.years$SeaLevel.x, y=tot.years$SeaLevel.y)
A2 = NonparEstDepFct(tot.years$SeaLevel.x, y=tot.years$SeaLevel.y, convex.hull = FALSE )
par(mfrow=c(2,1))
plot(A1)
plot(A2)
```

```{r Exercise 5.2}
## Data from Hall and Tajvidi (2004, ANZJS)
Estim1 <- NonparEstDepFct(x=tot.years$SeaLevel.x, y= tot.years$SeaLevel.y, convex = TRUE)

## Plot modified Pickands Function and area in which
## dependence function must lie
plot(Estim1, ylim = c(0.5,1), xlab = "w", ylab = "A(w)", type="l", lty="longdash")
polygon(c(0, 0.5, 1, 0), c(1, 0.5, 1, 1))

## Fit spline to Pickands function and add to plot
spline.fit <- SplineFitDepFct(Estim1)
curve(spline.fit, n = 301, add = TRUE, lty = "dashed")

```

```{r Exercise 5.3}

spline.cop = NewBEVSplineCopula(spline.fit)
spline.cop.approx = GetApprox(spline.cop)
plot(spline.cop.approx)

```

```{r Exercise 5.4}
RVs = GenerateRV(spline.cop.approx, 1000)
prob1.emp <- as.numeric(RVs[,1] > 1.7 & RVs[,2] > 4.2)
(prob1.emp = sum(prob1.emp)/length(prob1.emp))
```

```{r Exercise 6 type 1}
u1 = quantile(tot.years[,1], probs = 0.30)
u2 = quantile(tot.years[,2], probs = 0.30)

mod.sym = fbvpot(tot.years, threshold = c(u1,u2), model = c("log"))

mod.asym =  fbvpot(tot.years, threshold = c(u1,u2), model = c("aneglog"), std.err=FALSE)
plot(mod.sym, p=c(0.75,0.9,0.95), which = 3)
plot(mod.asym, p=c(0.75,0.9,0.95), which = 3)
#Very similar, kinda agree with 3.8
```

```{r exercise 6.4}

mtransform()

```






















